from urllib.parse import unquote
from fastapi.responses import RedirectResponse
import requests
import re
import time
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO
from bs4.element import Tag
from fastapi import FastAPI, HTTPException, Query, Request


app = FastAPI()



def fetch_page(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response
    except requests.RequestException as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}")
        return None

def check_title(soup, keyword):
    results = {
        'title_exists': '‚ùå –¢–µ–≥ Title –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.',
        'exact_keyword_in_title': '‚ùå –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–≥–µ Title.',
        'title_length': '‚ùå –¢–µ–≥ Title –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.',
    }

    title_tag = soup.title
    if title_tag and title_tag.string:
        title = title_tag.string.strip()
        results['title_exists'] = '‚úÖ –¢–µ–≥ Title –∑–∞–ø–æ–ª–Ω–µ–Ω.'
        results['exact_keyword_in_title'] = '‚úÖ –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞–π–¥–µ–Ω–∞!' if keyword.lower() in title.lower() else '‚ùå –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.'
        results['title_length'] = f'‚úÖ –î–ª–∏–Ω–∞ —Ç–µ–≥–∞ Title —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {len(title)} —Å–∏–º–≤–æ–ª–æ–≤, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.' if len(title) <= 60 else f'‚ùå –î–ª–∏–Ω–∞ —Ç–µ–≥–∞ Title —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {len(title)} —Å–∏–º–≤–æ–ª–æ–≤, —á—Ç–æ –º–µ–Ω—å—à–µ —Ç—Ä–µ–±—É–µ–º–æ–≥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.'

    return results

def check_keywords(soup, keyword):
    results = {
        'keywords_exists': '‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞!',
        'exact_keyword_in_keywords': '‚ùå –ù–µ—Ç —Ç–æ—á–Ω–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π —Ñ—Ä–∞–∑—ã',
        'keywords_fragment_count': 0,
        'keywords_length': 0
    }

    keywords_tag = soup.find('meta', attrs={'name': 'keywords'})
    if keywords_tag and keywords_tag.get('content'):
        keywords_content = keywords_tag['content'].strip()
        results['keywords_exists'] = '‚úÖ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞–π–¥–µ–Ω—ã!'
        results['exact_keyword_in_keywords'] = '‚úÖ –¢–æ—á–Ω–∞—è –∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–≥–µ keywords .' if keyword.lower() in keywords_content.lower() else '‚ùå –ù–µ—Ç —Ç–æ—á–Ω–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π —Ñ—Ä–∞–∑—ã'
        results['keywords_fragment_count'] = f"üî¢ –í—Å–µ–≥–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords_content.split(','))}"
        results['keywords_length'] = f"üìè –î–ª–∏–Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å–æ—Ç—Å—Ç–∞–≤–ª—è–µ—Ç: {len(keywords_content)}"

    return results

def check_description(soup, keyword):
    results = {
        'description_exists': '‚ùå –¢–µ–≥ Description –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.',
        'exact_keyword_in_description': '‚ö†Ô∏è –¢–æ—á–Ω–∞—è –∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–≥–µ Description.',
        'description_length': 0
    }

    description_tag = soup.find('meta', attrs={'name': 'description'})
    if description_tag and description_tag.get('content'):
        description_content = description_tag['content'].strip()
        results['description_exists'] = 'üéâ –¢–µ–≥ Description –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç.'
        results['exact_keyword_in_description'] = '‚úÖ –¢–æ—á–Ω–∞—è –∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–≥–µ Description.' if  keyword.lower() in description_content.lower() else '‚ö†Ô∏è –¢–æ—á–Ω–∞—è –∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–≥–µ Description.'
        results['description_length'] = f"‚ú® –û–±—â–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–≥–∞ Description: {len(description_content)}"

    return results

def check_language(soup):
    results = {
        'lang_set': '‚ùå –Ø–∑—ã–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.',
        'lang_value': '‚ùå –Ø–∑—ã–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.'
    }

    html_tag = soup.find('html')
    if html_tag and html_tag.has_attr('lang'):
        results['lang_set'] = 'üåê –Ø–∑—ã–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.'
        results['lang_value'] = f"'üåê –Ø–∑—ã–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {html_tag['lang']}"

    return results

def check_charset(response):
    results = {
        'charset_set': '‚ùå –ö–æ–¥–∏—Ä–æ–≤–∫–∞ utf-8 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.',
        'charset_value': '‚ùå –ö–æ–¥–∏—Ä–æ–≤–∫–∞ utf-8 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.'
    }

    content_type = response.headers.get('Content-Type', '')
    if 'charset=utf-8' in content_type.lower():
        results['charset_set'] = 'üéâ –ö–æ–¥–∏—Ä–æ–≤–∫–∞ utf-8 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.'
        results['charset_value'] = 'üéâ –ö–æ–¥–∏—Ä–æ–≤–∫–∞ utf-8 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.'

    return results

def check_h1(soup, keyword, title):
    results = {
        'h1_exists': '‚ùå –¢–µ–≥ H1 –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.',
        'exact_keyword_in_h1': '‚ö†Ô∏è –¢–æ—á–Ω–∞—è –∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ H1.',
        'matches_title': 'üîç –¢–µ–≥ H1 –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å Title.'
    }

    h1_tags = soup.find_all('h1')
    if h1_tags:
        results['h1_exists'] = 'üéâ –¢–µ–≥ H1 –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç.'
        for h1_tag in h1_tags:
            h1_text = h1_tag.get_text().strip()
            if keyword.lower() in h1_text.lower():
                results['exact_keyword_in_h1'] = '‚úÖ –¢–æ—á–Ω–∞—è –∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ H1.'
            if h1_text.lower() == title.lower():
                results['matches_title'] = 'üîÑ –¢–µ–≥ H1 —Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å Title.'

    return results

def check_article_tag(soup):
    results = {
        'article_tag_exists': "‚ùå –¢–µ–≥ article –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.",
        'content_in_article': '‚úÖ –í—Å—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ —Ç–µ–≥–∞.'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –µ—Å–ª–∏ —Ç–µ–≥–∞ <article> –Ω–µ—Ç, —Ç–æ —É—Å–ª–æ–≤–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
    }

    article_tag = soup.find('article')
    if article_tag:
        results['article_tag_exists'] = 'üéâ –¢–µ–≥ article –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞ <article>
        for child in article_tag.children:
            if child.name not in ['p', 'div', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'section']:
                results['content_in_article'] = '‚ö†Ô∏è –ù–µ –≤—Å—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞ article'
                break

    return results

def check_h2(soup, keyword):
    results = {
        'h2_count': '‚ö†Ô∏è –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö.',
        'keyword_in_h2': '‚ö†Ô∏è –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö.'
    }

    h2_tags = soup.find_all('h2')
    results['h2_count'] = len(h2_tags)

    if results['h2_count'] >= 2:
        results['h2_count'] = 'üéâ –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –µ—Å—Ç—å –∫–∞–∫ –º–∏–Ω–∏–º—É–º –¥–≤–∞ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞ H2.'
        for h2_tag in h2_tags:
            h2_text = h2_tag.get_text().strip()
            if keyword.lower() in h2_text.lower():
                results['keyword_in_h2'] = '‚úÖ –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ–¥–Ω–æ–º –∏–∑ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤.'
                break

    return results

def check_toc(soup):
    results = {
        'toc_exists': '‚ùå TOC –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.',
        'toc_correct': '‚ö†Ô∏è  TOC –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'
    }

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–µ–≥–∏ <h2>
    h2_tags = soup.find_all('h2')
    if h2_tags:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫ (–º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–ª–∏ –Ω–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤—ã–º <h2>
        first_h2 = h2_tags[0]
        previous_sibling = first_h2.find_previous_sibling()
        if previous_sibling and (previous_sibling.name == 'ul' or previous_sibling.name == 'ol'):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ <h2> –∏–º–µ—é—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID
            h2_ids = []
            for h2_tag in h2_tags:
                h2_id = h2_tag.get('id')
                if h2_id:
                    h2_ids.append(h2_id)
            if len(h2_ids) == len(set(h2_ids)):
                results['toc_correct'] = '‚úÖ TOC –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'

        results['toc_exists'] = '‚úÖ TOC –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'

    return results

def check_open_graph(soup):
    og_tags = {
        'og:title': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:description': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:url': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:type': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:image': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:site_name': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:action': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:property': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ",
        'og:event': "‚ùå –ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ"
    }

    for tag in og_tags.keys():
        og_tag = soup.find('meta', property=tag)
        if og_tag and og_tag.get('content'):
            og_tags[tag] = '‚úÖ –ó–∞–ø–æ–ª–Ω–µ–Ω–æ'

    return og_tags


def check_p_tags(soup, keyword):
    results = {
        'exact_keyword_in_first_p': '‚ùå –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –∏–ª–∏ —Å–µ—Ä–µ–¥–∏–Ω–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ P.',
        'exact_keyword_density': 0,
        'partial_keyword_density': 0,
        'p_length_limit_exceeded': 'üö´ –î–ª–∏–Ω–∞ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –±–æ–ª–µ–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ P –ø—Ä–µ–≤—ã—à–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.',
        'consecutive_p_count': 'üöß –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ P –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–∞–µ—Ç –¥–æ–ø—É—Å—Ç–∏–º–æ–µ.',
        'total_p_length': 0,
        'keyword_distribution_uniformity': False
    }

    p_tags = soup.find_all('p')
    keyword_lower = keyword.lower()
    total_text = ""
    total_exact_count = 0
    total_partial_count = 0
    max_p_length = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ p
    consecutive_p_limit = 3  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–¥—É—â–∏—Ö –ø–æ–¥—Ä—è–¥ p
    max_consecutive_p_count = 0
    current_consecutive_p_count = 0
    keyword_positions = []

    for i, p in enumerate(p_tags):
        p_text = p.get_text().strip()
        total_text += p_text + " "

        if i == 0:
            first_sentence = p_text.split('.')[0]
            if keyword_lower in first_sentence.lower():
                results['exact_keyword_in_first_p'] = 'üéØ –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ —Ç–æ—á–Ω–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –∏–ª–∏ —Å–µ—Ä–µ–¥–∏–Ω–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ P.'

        exact_count = p_text.lower().count(keyword_lower)
        total_exact_count += exact_count

        partial_count = sum([1 for word in p_text.lower().split() if keyword_lower in word])
        total_partial_count += partial_count

        if len(p_text) > max_p_length:
            results['p_length_limit_exceeded'] = 'üìè –î–ª–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ P –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã.'

        if p_text:
            current_consecutive_p_count += 1
        else:
            current_consecutive_p_count = 0

        max_consecutive_p_count = max(max_consecutive_p_count, current_consecutive_p_count)

        keyword_positions.extend([m.start() for m in re.finditer(keyword_lower, p_text.lower())])

    if max_consecutive_p_count > consecutive_p_limit:
        results['consecutive_p_count'] = 'üß© –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ P –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–æ–ø—É—Å—Ç–∏–º–æ.'

    total_length = len(total_text)
    results['total_p_length'] = f'üìú –û–±—â–∞—è –¥–ª–∏–Ω–∞ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ P: {total_length}' 
    results['exact_keyword_density'] = 'üîç –¢–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–π —Ñ—Ä–∞–∑—ã –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –Ω–µ –º–µ–Ω–µ–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞ –Ω–∞ 1,000 —Å–∏–º–≤–æ–ª–æ–≤.' if total_exact_count / (total_length / 1000) >= 1 else '‚ö†Ô∏è –¢–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–π —Ñ—Ä–∞–∑—ã —Ä–µ–∂–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞ –Ω–∞ 1,000 —Å–∏–º–≤–æ–ª–æ–≤.'
    results['partial_keyword_density'] = total_partial_count / (total_length / 1000)

    if len(keyword_positions) > 1:
        intervals = [keyword_positions[i + 1] - keyword_positions[i] for i in range(len(keyword_positions) - 1)]
        avg_interval = sum(intervals) / len(intervals)
        uniformity_threshold = avg_interval * 0.5

    return results

def check_lists(soup):
    results = {
        'lists_between_p': '‚ùå –°–ø–∏—Å–∫–∏ (UL, OL) –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –º–µ–∂–¥—É —Ç–µ–≥–∞–º–∏ P',
        'lists_in_article': False
    }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–ø–∏—Å–∫–æ–≤ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ <p>
    p_tags = soup.find_all('p')
    ul_tags = soup.find_all('ul')
    ol_tags = soup.find_all('ol')

    for i in range(len(p_tags) - 1):
        p1 = p_tags[i]
        p2 = p_tags[i + 1]
        lists_between = p1.find_next_siblings(['ul', 'ol'], limit=1)
        if lists_between and lists_between[0] != p2:
            results['lists_between_p'] = 'üìã –°–ø–∏—Å–∫–∏ (UL, OL) –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –º–µ–∂–¥—É —Ç–µ–≥–∞–º–∏ P'
            break

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–ø–∏—Å–∫–æ–≤ –≤–Ω—É—Ç—Ä–∏ <article>
    article_tag = soup.find('article')
    if article_tag:
        if article_tag.find_all(['ul', 'ol']):
            results['lists_in_article'] = True

    return results

def check_tables(soup):
    results = {
        'tables_between_p': '‚ùå –¢–∞–±–ª–∏—Ü—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –º–µ–∂–¥—É —Ç–µ–≥–∞–º–∏',
        'tables_in_article': False
    }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ <p>
    p_tags = soup.find_all('p')
    table_tags = soup.find_all('table')

    for i in range(len(p_tags) - 1):
        p1 = p_tags[i]
        p2 = p_tags[i + 1]
        tables_between = p1.find_next_siblings('table', limit=1)
        if tables_between and tables_between[0] != p2:
            results['tables_between_p'] = 'üìù –¢–∞–±–ª–∏—Ü—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–µ–∂–¥—É —Ç–µ–≥–∞–º–∏ P'
            break

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –≤–Ω—É—Ç—Ä–∏ <article>
    article_tag = soup.find('article')
    if article_tag:
        if article_tag.find_all('table'):
            results['tables_in_article'] = True

    return results

def is_image_visible(img_tag):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∏–¥–∏–º–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    styles = img_tag.get('style', '')
    if 'display: none' in styles:
        return False
    parent_tags = img_tag.find_parents()
    for parent in parent_tags:
        parent_style = parent.get('style', '')
        if 'display: none' in parent_style:
            return False
    noscript_parent = img_tag.find_parent('noscript')
    if noscript_parent:
        return False
    return True

def check_images(soup, keyword):
    results = {
        'image_count_per_3000_chars': 0,
        'all_images_have_alt': '‚úÖ –í—Å–µ —Ç–µ–≥–∏ ALT –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.',
        'keyword_in_alt': 'üîé –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ ALT.',
        'image_formats': 'üì∑ –§–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.',
        'image_size_within_limit': '‚öñÔ∏è –í–µ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã.'
    }

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤
    text = soup.get_text()
    char_count = len(text)

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–µ–≥–∏ <img>
    img_tags = soup.find_all('img')
    visible_img_tags = [img for img in img_tags if is_image_visible(img)]

    total_images = len(visible_img_tags)
    if char_count > 0:
        results['image_count_per_3000_chars'] = 'üñºÔ∏è –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.' if total_images / (char_count / 3000) >=1 else '‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º alt –∞—Ç—Ä–∏–±—É—Ç—ã –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
    for img in visible_img_tags:
        alt = img.get('alt', '').strip()
        if not alt:
            results['all_images_have_alt'] = '‚ö†Ô∏è –ù–µ –≤—Å–µ —Ç–µ–≥–∏ ALT –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.'
        if keyword.lower() in alt.lower():
            results['keyword_in_alt'] = 'üîç –ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ–¥–Ω–æ–º –∏–∑ ALT.'

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∏ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        src = img.get('src', '')
        try:
            response = requests.get(src)
            if response.status_code == 200:
                image_data = BytesIO(response.content)
                img = Image.open(image_data)
                width, height = img.size
                file_format = img.format.lower()
                if file_format not in ['webp', 'jpeg', 'jpg', 'png']:
                    results['image_formats'] = 'üñºÔ∏è –§–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.'
                if width * height > 100 * 100 and len(response.content) > 100 * 100:
                    results['image_size_within_limit'] = 'üìè –í–µ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–µ–≤—ã—à–∞–µ—Ç –¥–æ–ø—É—Å—Ç–∏–º—ã–π.'
        except Exception as e:
            print(f"Error checking image {src}: {e}")

    return results

# def check_formatting_tags(soup, keyword):
#     results = {
#         'tags_present':'‚ùå –¢–µ–≥–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.',
#         'exact_keyword_in_tags': '‚ö†Ô∏è –¢–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.',
#         'partial_keyword_in_tags': 'üö´ –ù–µ —Ç–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'
#     }

#     # –ü–æ–∏—Å–∫ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
#     tags_to_check = ['b', 'strong', 's', 'i', 'u', 'span']
#     for tag_name in tags_to_check:
#         tag_elements = soup.find_all(tag_name)
#         if tag_elements:
#             results['tags_present'][tag_name] = 'üé® –¢–µ–≥–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.'
#             for tag in tag_elements:
#                 text = tag.get_text().lower()
#                 if keyword.lower() in text:
#                     results['exact_keyword_in_tags'][tag_name] = 'üè∑Ô∏è –¢–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞–π–¥–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'
#                 if keyword.lower()[:-1] in text or keyword.lower()[1:] in text:
#                     results['partial_keyword_in_tags'][tag_name] = 'üîç –ù–µ —Ç–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–∞–∫–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'

#     return results

def check_formatting_tags_and_keywords(soup, keyword):
    tags_to_check = ['b', 'strong', 's', 'i', 'u', 'span']
    formatting_tags_present = '‚ùå –¢–µ–≥–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.'
    exact_keyword_found = '‚ö†Ô∏è –¢–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'
    partial_keyword_found = 'üö´ –ù–µ —Ç–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'

    for tag_name in tags_to_check:
        tag_elements = soup.find_all(tag_name)
        if tag_elements:
            formatting_tags_present = 'üé® –¢–µ–≥–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.'
            for tag in tag_elements:
                text = tag.get_text().lower()
                if keyword.lower() in text:
                    exact_keyword_found = 'üè∑Ô∏è –¢–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞–π–¥–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'
                if keyword.lower()[:-1] in text or keyword.lower()[1:] in text:
                    partial_keyword_found = 'üîç –ù–µ —Ç–æ—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–∞–∫–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.'
            # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –≤—Å–µ –Ω—É–∂–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
            if formatting_tags_present and exact_keyword_found and partial_keyword_found:
                break

    return {
        'formatting_tags_present': formatting_tags_present,
        'exact_keyword_in_formatting_tags': exact_keyword_found,
        'partial_keyword_in_formatting_tags': partial_keyword_found
    }

def check_links(soup, keyword):
    external_links_present = '‚ùå –í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.'
    internal_links_present = 'üö´ –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.'
    exact_keyword_in_anchor = '‚ùó –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–∫–∏.'
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö —Ç–µ–≥–æ–≤ <a> –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤–Ω–µ—à–Ω–∏—Ö –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
    for a_tag in soup.find_all('a', href=True):
        href = a_tag.get('href')
        if href.startswith('http'):
            external_links_present = 'üåê –í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞–π–¥–µ–Ω—ã.'
        else:
            internal_links_present = 'üîó –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.'

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞ —Å—Å—ã–ª–∫–∏
        anchor_text = a_tag.get_text().lower()
        if keyword.lower() in anchor_text:
            exact_keyword_in_anchor = 'üîç –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ —Ç–æ—á–Ω–æ –Ω–∞–π–¥–µ–Ω–æ –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–∫–∏.'

        # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞, –µ—Å–ª–∏ –≤—Å–µ –Ω—É–∂–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–π–¥–µ–Ω—ã
        if external_links_present and internal_links_present and exact_keyword_in_anchor :
            break

    return {
        'external_links_present': external_links_present,
        'internal_links_present': internal_links_present,
        'exact_keyword_in_anchor': exact_keyword_in_anchor,
    }

def check_text_size_ratio(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')
    text_length = len(soup.get_text())
    html_length = len(str(soup))

    words_count = len(soup.get_text().split())
    characters_count = len(soup.get_text())

    text_code_ratio = '‚öñÔ∏è –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫ —Å–∏–º–≤–æ–ª–∞–º –∫–æ–¥–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ.' if text_length / html_length >= 0.2 else 'üìâ –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫ —Å–∏–º–≤–æ–ª–∞–º –∫–æ–¥–∞ –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ.'

    return {
        'words_count': f"üìÑ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {words_count}",
        'characters_count': f"‚úèÔ∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {characters_count}",
        'text_code_ratio': text_code_ratio
    }

def check_page_speed_and_size(url):
    try:
        start_time = time.time()
        response = requests.get(url)
        end_time = time.time()
        page_load_time = end_time - start_time

        if response.status_code == 200:
            page_size = len(response.content) / 1024  # —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –∫–∏–ª–æ–±–∞–π—Ç–∞—Ö
            return {
                'page_load_time_seconds': 'üöÄ –°–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–ª–∏—á–Ω–∞—è.' if page_load_time <= 2 else 'üê¢ –°–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–µ–¥–ª–µ–Ω–Ω–∞—è.',
                'page_size_kb': page_size
            }
        else:
            return {
                'page_load_time_seconds': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}",
                'page_size_kb': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}"
            }

    except requests.exceptions.RequestException:
        return {
            'page_load_time_seconds': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}",
            'page_size_kb': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}"
        }
    
def check_iframe(soup):
    iframe_present = 'üéâ –¢–µ–≥ iframe –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'
    if soup.find('iframe'):
        iframe_present = '‚ùå –¢–µ–≥ iframe –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'

    return iframe_present

def check_shockwave_flash(soup):
    flash_present = '‚ùå Shockwave Flash –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–≥–∏ object –∏ embed, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã —Å Flash
    object_tags = soup.find_all('object', type='application/x-shockwave-flash')
    embed_tags = soup.find_all('embed', type='application/x-shockwave-flash')

    if object_tags or embed_tags:
        flash_present = '‚úÖ –ù–∞–ª–∏—á–∏–µ Shockwave Flash –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ.'

    return flash_present

def check_favicon(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            favicon_tags = soup.find_all('link', rel='icon') + soup.find_all('link', rel='shortcut icon')

            has_favicon = '‚úÖ Favicon –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.' if any(tag.get('href') for tag in favicon_tags) else '‚ùå Favicon –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.'

            has_svg_favicon = 'üñºÔ∏è –ò–∫–æ–Ω–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SVG –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞.' if any(tag.get('href').endswith('.svg') for tag in favicon_tags) else 'üö´ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–∫–æ–Ω–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SVG.'

            return {
                'has_favicon': has_favicon,
                'has_svg_favicon': has_svg_favicon
            }
        else:
            return {
                'has_favicon': '‚ùå Favicon –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.',
                'has_svg_favicon': 'üö´ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–∫–æ–Ω–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SVG.'
            }

    except requests.exceptions.RequestException:
        return {
            'has_favicon': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}",
            'has_svg_favicon': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å URL: {e}"
        }


def check_scripts_at_bottom(soup):
    body_tag = soup.body
    if not body_tag:
        return '‚ùå –°–∫—Ä–∏–ø—Ç –Ω–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤–Ω–∏–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã.  # –ï—Å–ª–∏ —Ç–µ–≥ <body> –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, —Ç–æ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç—ã –Ω–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤–Ω–∏–∑—É'

    script_tags = soup.find_all('script')

    for script_tag in script_tags:
        if script_tag.parent != body_tag:
            return '‚ùå –°–∫—Ä–∏–ø—Ç –Ω–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤–Ω–∏–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã.' # –ï—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞ <body>, —Ç–æ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç—ã –Ω–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤–Ω–∏–∑—É
        if script_tag.find_next_sibling():  # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Å–æ—Å–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç, —Ç–æ —Å–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω–∏–∑—É
            return '‚ùå –°–∫—Ä–∏–ø—Ç –Ω–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤–Ω–∏–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã.'

    return 'üéâ –°–∫—Ä–∏–ø—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤–Ω–∏–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã.'

def check_analytics(soup):
    analytics = {
        'yandex_metrika': 'üö´ –Ø–Ω–¥–µ–∫—Å –ú–µ—Ç—Ä–∏–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.',
        'google_analytics': 'üìâ Google Analytics –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.',
        'vk_pixel': 'üìµ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç VK pixel.'
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ –Ø–Ω–¥–µ–∫—Å –ú–µ—Ç—Ä–∏–∫–∞
    yandex_metrika_scripts = soup.find_all('script', src=lambda x: x and 'mc.yandex.ru/metrika' in x)
    yandex_metrika_noscripts = soup.find_all('noscript', div=lambda x: x and 'mc.yandex.ru/metrika' in x)

    if yandex_metrika_scripts or yandex_metrika_noscripts:
        analytics['yandex_metrika'] = 'üîç –Ø–Ω–¥–µ–∫—Å –ú–µ—Ç—Ä–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞.'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ Google Analytics
    google_analytics_scripts = soup.find_all('script', src=lambda x: x and 'google-analytics.com/analytics' in x)

    if google_analytics_scripts:
        analytics['google_analytics'] = 'üìà Google Analytics —Ä–∞–±–æ—Ç–∞–µ—Ç.'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ VK pixel
    vk_pixel_scripts = soup.find_all('script', src=lambda x: x and 'vk.com/js/api/openapi.js' in x)

    if vk_pixel_scripts:
        analytics['vk_pixel'] = 'üì± VK pixel —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.'

    return analytics

def check_crm(soup):
    crm = {
        'bitrix24': 'üö´ –ë–∏—Ç—Ä–∏–∫—Å24 –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω',
        'amo': 'üö´ –ê–º–æ –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω'
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ –ë–∏—Ç—Ä–∏–∫—Å24
    bitrix24_scripts = soup.find_all('script', src=lambda x: x and 'bitrix24' in x)

    if bitrix24_scripts:
        crm['bitrix24'] = 'üìà –ë–∏—Ç—Ä–∏–∫—Å24 –ø–æ–¥–∫–ª—é—á–µ–Ω.'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ AMO
    amo_scripts = soup.find_all('script', src=lambda x: x and 'amocrm' in x)

    if amo_scripts:
        crm['amo'] = 'üìà –ê–º–æ –ø–æ–¥–∫–ª—é—á–µ–Ω'

    return crm


def check_cms(soup):
    cms = {
        'wordpress': '‚ùå –°–∞–π—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ WordPress.',
        'tilda': '‚ùå –°–∞–π—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Tilda.',
        '1c_bitrix': '‚ùå –°–∞–π—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ 1C-Bitrix.'
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ WordPress
    wordpress_meta_generator = soup.find('meta', {'name': 'generator', 'content': 'WordPress'})

    if wordpress_meta_generator:
        cms['wordpress'] = '‚úÖ –°–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ WordPress'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ Tilda
    tilda_scripts = soup.find_all('script', src=lambda x: x and 'tilda.cc' in x)

    if tilda_scripts:
        cms['tilda'] = '‚úÖ –°–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Tilda.'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ 1C-Bitrix
    bitrix1c_scripts = soup.find_all('script', src=lambda x: x and 'bitrix' in x)

    if bitrix1c_scripts:
        cms['1c_bitrix'] = '‚úÖ –°–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ 1C-Bitrix.'

    return cms




def seo_analysis(url, keyword):
    response = fetch_page(url)
    if response is None:
        return {'error': 'Unable to fetch the page.'}

    content_type = response.headers.get('Content-Type', '').lower()
    if 'text/html' not in content_type:
        return {'error': 'The URL does not point to an HTML page.'}

    content = response.content
    soup = BeautifulSoup(content, 'html.parser')

    title_results = check_title(soup, keyword)
    keywords_results = check_keywords(soup, keyword)
    description_results = check_description(soup, keyword)
    language_results = check_language(soup)
    charset_results = check_charset(response)
    h1_results = check_h1(soup, keyword, title_results.get('title', ''))
    article_results = check_article_tag(soup)
    h2_results = check_h2(soup, keyword)
    toc_results = check_toc(soup)
    open_graph_results = check_open_graph(soup)
    p_tag_results = check_p_tags(soup, keyword)
    list_results = check_lists(soup)
    table_results = check_tables(soup)
    image_results = check_images(soup, keyword)
    formatting_tags_keywords = check_formatting_tags_and_keywords(soup, keyword)
    links_results = check_links(soup, keyword)
    text_size_ratio_results = check_text_size_ratio(response.content)
    text_size_ratio_results = check_text_size_ratio(response.content)
    page_speed_and_size_results = check_page_speed_and_size(url) 
    iframe_results = check_iframe(soup)
    shockwave_flash_results = check_shockwave_flash(soup)
    favicon_results = check_favicon(url)
    scripts_at_bottom_results = check_scripts_at_bottom(soup)
    analytics_results = check_analytics(soup)
    crm_results = check_crm(soup)
    cms_results = check_cms(soup)

    return  {
        'title': title_results,
        'keywords': keywords_results,
        'description': description_results,
        'language': language_results,
        'charset': charset_results,
        'h1': h1_results,
        'article': article_results,
        'h2': h2_results,
        'toc': toc_results,
        'open_graph': open_graph_results,
        'p_tags': p_tag_results,
        'lists': list_results,
        'tables': table_results,
        'images': image_results,
        'formatting_tags_keywords': formatting_tags_keywords,
        'links': links_results,
        'text_size_ratio': text_size_ratio_results,
        'text_size_ratio': text_size_ratio_results,
        'page_speed_and_size': page_speed_and_size_results,
        'iframe': iframe_results,
        'shockwave_flash': shockwave_flash_results,
        'favicon': favicon_results,
        'scripts_at_bottom': scripts_at_bottom_results,
        'analytics': analytics_results,
        'crm': crm_results,
        'cms': cms_results,
        
    }




@app.get("/seo-analysis/")
async def seo_analysis(url: str = Query(..., description="URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"),
                        keyword: str = Query(..., description="–ö–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")):
    try:
        response = fetch_page(url)
    
        if response is None:
            return {'error': 'Unable to fetch the page.'}

        content_type = response.headers.get('Content-Type', '').lower()
        if 'text/html' not in content_type:
            return {'error': 'The URL does not point to an HTML page.'}

        content = response.content
        soup = BeautifulSoup(content, 'html.parser')

        title_results = check_title(soup, keyword)
        keywords_results = check_keywords(soup, keyword)
        description_results = check_description(soup, keyword)
        language_results = check_language(soup)
        charset_results = check_charset(response)
        h1_results = check_h1(soup, keyword, title_results.get('title', ''))
        article_results = check_article_tag(soup)
        h2_results = check_h2(soup, keyword)
        toc_results = check_toc(soup)
        open_graph_results = check_open_graph(soup)
        p_tag_results = check_p_tags(soup, keyword)
        list_results = check_lists(soup)
        table_results = check_tables(soup)
        image_results = check_images(soup, keyword)
        formatting_tags_keywords = check_formatting_tags_and_keywords(soup, keyword)
        links_results = check_links(soup, keyword)
        text_size_ratio_results = check_text_size_ratio(response.content)
        text_size_ratio_results = check_text_size_ratio(response.content)
        page_speed_and_size_results = check_page_speed_and_size(url) 
        iframe_results = check_iframe(soup)
        shockwave_flash_results = check_shockwave_flash(soup)
        favicon_results = check_favicon(url)
        scripts_at_bottom_results = check_scripts_at_bottom(soup)
        analytics_results = check_analytics(soup)
        crm_results = check_crm(soup)
        cms_results = check_cms(soup)
        check_keywords_result = check_keywords(soup, keyword)
            

        return {
            'title': title_results,
        'keywords': keywords_results,
        'description': description_results,
        'language': language_results,
        'charset': charset_results,
        'h1': h1_results,
        'article': article_results,
        'h2': h2_results,
        'toc': toc_results,
        'open_graph': open_graph_results,
        'p_tags': p_tag_results,
        'lists': list_results,
        'tables': table_results,
        'images': image_results,
        'formatting_tags_keywords': formatting_tags_keywords,
        'links': links_results,
        'text_size_ratio': text_size_ratio_results,
        'text_size_ratio': text_size_ratio_results,
        'page_speed_and_size': page_speed_and_size_results,
        'iframe': iframe_results,
        'shockwave_flash': shockwave_flash_results,
        'favicon': favicon_results,
        'scripts_at_bottom': scripts_at_bottom_results,
        'analytics': analytics_results,
        'crm': crm_results,
        'cms': cms_results,
        }
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)